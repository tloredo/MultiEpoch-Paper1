%--------------------------------------------------------------------------------
\iffalse
\subsection{Mixed Detections of Object and Noise}
\label{sec:mix}
\noindent
The faintest sources rarely pop above the threshold, which makes them apparently more distiguishable from the noise, as seen previously in Figure~\ref{fig:bf}. This is a real effect due to the fact that the noise peaks tend to be higher flux; see details in the Appendix. In a real survey, candidate associations of faint sources are expected to be contaminated  by noise peaks. To deal with this, we can  extend our model to include a label parameter $v_i$ for each detection, which takes the value of, say, 1 if the detection is from the object, and 0 if it is a ghost.
%
Formally this is similar to sorting the measurements into correct and incorrect classes for robust measurements, as discussed by \citet{press}.
%
The likelihood is a product of the two possibilities, which is a function of the set of labels $\apjvec{v}$ and the flux.
%
\begin{equation}
L(\apjvec{v},f)= (1\!-\!P_f)^{k\!-\!n} \prod_{v_i=1}\!G(f_i;f,\sigma^2) \prod_{v_i=0}\!(1\!-\!P_f)\,N(f_i;\sigma^2)
\end{equation}
%
If $\beta$ represents the probability that a detection belongs to the object, the conditional probability of $\apjvec{v}$ is
%
\begin{equation}
\pi(\apjvec{v}|\beta) = \prod_{v_i=1}\!\beta \prod_{v_i=0}\!(1\!-\!\beta)
\end{equation}
%
Not knowing the value of $\beta$ we can assume its prior to be flat on the [0,1] interval to derive the posterior probability, which can be marginalized to find the best labels. Also we can perform the full integration over all parameters to use for hypothesis testing.
%
\begin{eqnarray}
L_{\text{mix}} & = & \int_0^1\!\!d\beta \int\!\!df\,\pi(f)\ (1\!-\!P_f)^{k\!-\!n} \ \times\\
 & \times & \sum_{\apjvec{v}}\prod_{v_i=1}\!\beta G(f_i;f,\sigma^2) \prod_{v_i=0}\!(1\!-\!\beta)(1\!-\!P_f)\,N(f_i;\sigma^2) \nonumber \\
 & = & \int_0^1\!\!d\beta \int\!\!df\ \pi(f)\ (1\!-\!P_f)^{k\!-\!n}  \ \times \\
 & \times & \prod_i \Big[\beta G(f_i;f,\sigma^2) + (1\!-\!\beta)(1\!-\!P_f)\,N(f_i;\sigma^2) \Big] \nonumber
\end{eqnarray}
%
In confused fields this can be further extended to include the possiblity of multiple objects \citep{loredo}.



\iffalse
\begin{figure}
\epsscale{1.2}
\plotone{fig/f9.png}
\caption{The Bayes factor increases for the simulate noise peaks as we increase their surface density. These simulations illustrate that effect for 1$\times$, 2$\times$, ..., and 5$\times$ the original density used in Figure~\ref{fig:bf2}. The highest density of about 3/$\square\arcsec$ corresponds roughly to 1 peak in 9 pixels for images with 0.5\arcsec pixels, which can be considered the absolute limit.}
\label{fig:bfx}
\end{figure}
\fi



%--------------------------------------------------------------------------------
\subsection{Variable Objects}
\label{sec:var}
\noindent
While the analysis here considered only sources with constant brightness, the methodology is expected to perform well on variables. If the brightening is a one-time transient such as a supernova, the significance comes from the measured flux providing enough evidence for keeping the detections.
%
If, on the other hand, the variables are repeatedly detected, the cross-identification term will quickly grow to high values. The details of such algorithms will need to be optimized with the observation cadence and the expected frequency of these sources, hence here we just provide the general mathematical formulas.
%
A model that describes the evolution of the flux is parameterized by some $\theta$ variables, such that $g(t;\theta)$ provides the prediction of the true flux as a function of time. Examples include models for supernova lightcurves empirical or theoretical \citep{riess95,snana}. The $\pi(\theta)$ distribution is either known apriori or can be inferred simultaneously in a 2-level hierarchical model.
%
Let $i$ index the epochs at which we detect the $f_i$ fluxes, and $j$ reprensent the remaining $m$ exposures where nothing is seen.
%
Similarly to the constant flux model we can formulate the likelihood function that will also depend on the epochs now. The probability of detecting a variable object at $t_j$ time having
\mbox{$g_j(\theta)\equiv{}g(t_j;\theta)$} flux is the integral above the threshold, $P_{g_j(\theta)}$, cf.\ Eq.(\ref{eq:pf}), and the likelihood of  $\theta$ is
%
\begin{equation}
L(\theta) = \prod_j^{k-n} \left[1\!-\!P_{g_j(\theta)}\right]\,\prod_i^n G\big(f_i;g_i(\theta),\sigma^2\big)
\end{equation}
%
The likehood of the hypothesis is given by marginalizing over all parameters,
%
\begin{equation}
L_{\rm{}var} = \int{}\!\!d\theta\,\pi(\theta)\,L(\theta)
\end{equation}
%
which can be compared to the noise or constant flux hypotheses.
%
We note that the latter is a special case of this generalization.
If we simply assume that there is no time-dependence and \mbox{$g(t;\theta)\!=\!\theta$} then we get the same formulas with \mbox{$\theta\!\equiv{}\!f$}.

Periodic objects fall in a special case where time is folded onto a fix interval, say between 0 and 1. With $\omega$ frequency and $\phi$ phase broken out from the general $\theta$ parameters, i.e., \mbox{$\theta\!=\!(\omega,\phi,\theta')$}, the time-dependence has the specific form of
%
\begin{equation}
g(t;\omega,\phi,\theta') = h(x;\theta')
\end{equation}
with
\begin{equation}
x = \frac{ (\omega{}t+\phi)\,{\rm{}mod}\,{2\pi} }{2\pi}
\end{equation}
%
where $h(\cdot)$ describes the shape of the periodic signal, parameterized by $\theta'$, which repeats indefinitely.
%
For example, \citet{gregory} approximate the shape with piecewise constants in $m$ bins, where $m$ is also a variable, and develop an elegant method for detecting periodic signals.
%
They discuss the invariance argument that formally yields the priors
\begin{eqnarray}
\pi(\phi) & = & 1 \big/ 2\pi \\
\pi(\omega)& \propto & 1 \big/ \omega
\end{eqnarray}
on the new parameters.
%
The non-uniform prior on the frequency can be shown to be the natural choice that is also form-invariant with respect to re-parametrization in terms of the period; see \citet{gregory} and references therein.

%%%%%%%% From summary:

explored new approaches to processing a series of exposures with special focus on the faintest sources, where most of the new discoveries are expected.
%
We found that one can recover sources just by collecting a number of detections above even a low threshold with the same probability as if the sources were extracted from coadded images. Consequently we can develop incremental algorithms that crossmatch the detections and weed out the noise on the fly from a master source catalog.
